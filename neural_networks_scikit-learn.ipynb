{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary packages and data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # Numerical computation package\n",
    "from sklearn.neural_network import MLPRegressor # multilayer perceptron regressor and classifier\n",
    "from sklearn.preprocessing import StandardScaler # helper to scale our data\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important!! use index_col=0 to read df otherwise pca starts at col 58\n",
    "ped = pd.read_csv(\"data_clean_with_dummies.csv\", index_col=0)\n",
    "\n",
    "# beginning of the code, so everyone has the same\n",
    "np.random.seed(1) # Set the random seed for reproduceability\n",
    "\n",
    "\n",
    "# Define a new X with the squared feature and choose only columns that we need for enough variance\n",
    "X = np.array(ped[ped.columns[57:]])\n",
    "\n",
    "# Output to predict\n",
    "y = ped[\"pedestrians count\"]\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the neural network to predict the pedestrians given our different features\n",
    "# use three hidden layers, with sizes 32, 64, and 32, ReLU activation functions,\n",
    "# stochastic gradient descent optimization and a regularization paramater\n",
    "# (lambda or alpha) of 0.001, batchsizes of 32 and 1000 epochs\n",
    "nnet = MLPRegressor(hidden_layer_sizes=(32, 64, 32), activation=\"relu\", solver=\"sgd\",\n",
    "                    alpha=0.001, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data so it is less sensitive to feature scaling\n",
    "scaler = StandardScaler()\n",
    "# scale the inputs\n",
    "scaler.fit(Xtrain)\n",
    "Xtrain = scaler.transform(Xtrain)\n",
    "# apply the same transformation to the test data to have meaningful results\n",
    "Xtest = scaler.transform(Xtest)\n",
    "\n",
    "# scale the y different because we can't use standardscaler to a 1d array\n",
    "# scale the output\n",
    "mu, sigma = y.mean(), y.std() # We will use this to scale back to original values!\n",
    "ytest = (ytest - mu) / sigma\n",
    "ytrain = (ytrain - mu) /sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janag\\miniconda3\\envs\\dsf\\lib\\site-packages\\sklearn\\neural_network\\_base.py:174: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "c:\\Users\\janag\\miniconda3\\envs\\dsf\\lib\\site-packages\\sklearn\\utils\\extmath.py:152: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\janag\\miniconda3\\envs\\dsf\\lib\\site-packages\\sklearn\\utils\\extmath.py:152: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\janag\\miniconda3\\envs\\dsf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\janag\\OneDrive\\HSG\\HS22\\DSF\\Projekt\\dsf_project\\neural_networks_scikit-learn.ipynb Zelle 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janag/OneDrive/HSG/HS22/DSF/Projekt/dsf_project/neural_networks_scikit-learn.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Fit the network to the train data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/janag/OneDrive/HSG/HS22/DSF/Projekt/dsf_project/neural_networks_scikit-learn.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nnet\u001b[39m.\u001b[39;49mfit(Xtrain, ytrain)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janag/OneDrive/HSG/HS22/DSF/Projekt/dsf_project/neural_networks_scikit-learn.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/janag/OneDrive/HSG/HS22/DSF/Projekt/dsf_project/neural_networks_scikit-learn.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ypred \u001b[39m=\u001b[39m nnet\u001b[39m.\u001b[39mpredict(Xtest)\n",
      "File \u001b[1;32mc:\\Users\\janag\\miniconda3\\envs\\dsf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:762\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m    746\u001b[0m     \u001b[39m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \n\u001b[0;32m    748\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[39m        Returns a trained MLP model.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, incremental\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\janag\\miniconda3\\envs\\dsf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:448\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    446\u001b[0m weights \u001b[39m=\u001b[39m chain(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoefs_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercepts_)\n\u001b[0;32m    447\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(np\u001b[39m.\u001b[39misfinite(w)\u001b[39m.\u001b[39mall() \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m weights):\n\u001b[1;32m--> 448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    449\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSolver produced non-finite parameter weights. The input data may\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    450\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m contain large values and need to be preprocessed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    453\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed."
     ]
    }
   ],
   "source": [
    "# Fit the network to the train data\n",
    "nnet.fit(Xtrain, ytrain)\n",
    "\n",
    "# Make predictions\n",
    "ypred = nnet.predict(Xtest)\n",
    "\n",
    "# Reconstruct outputs and scale predictions\n",
    "ytest = ytest * sigma + mu\n",
    "ytrain = ytrain * sigma + mu\n",
    "ypred = ypred * sigma + mu\n",
    "\n",
    "\n",
    "# Compute the MAE\n",
    "mae = mean_absolute_error(ytest, ypred)\n",
    "# Comute R^2\n",
    "r2 = r2_score(ytest, ypred)\n",
    "\n",
    "print(f\"The mean absolute error is {mae}\")\n",
    "print(f\"The R^2 is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error is 525.9776290853022\n",
    "The R^2 is 0.928619546779347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "#create a linspace to match the y-values\n",
    "xs = np.linspace(0, ytest.shape[0], num=ytest.shape[0])\n",
    "\n",
    "# plot the true values for 2 pca variables\n",
    "ax.scatter(xs, ytest, label=\"true values\", alpha=0.8)\n",
    "\n",
    "# plot the predictions\n",
    "ax.scatter(xs, ypred, label=\"predictions\", color = \"red\", alpha=0.2)\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel(\"Features\")\n",
    "ax.set_ylabel(\"Pedestrians\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data so it is less sensitive to feature scaling\n",
    "scaler = StandardScaler()\n",
    "# scale the inputs\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# scale the y different because we can't use standardscaler to a 1d array\n",
    "mu, sigma = y.mean(), y.std() # We will use this to scale back to original values!\n",
    "y = (y - mu) / sigma\n",
    "\n",
    "# create custom scoring function\n",
    "#def scorer(estimator, x, y):\n",
    "    #ypred = estimator.predict(x)\n",
    "    #mae = np.sum(np.abs(ypred - y))\n",
    "    #r2 = r2_score(y, ypred)\n",
    "    #return (mae, r2)\n",
    "\n",
    "# create function to put in loop\n",
    "#def train_and_test(hidden_layer, activation_function, solver, alpha, max_iteration):\n",
    "    #nnet = MLPRegressor(hidden_layer_sizes=hidden_layer, activation=activation_function, solver=solver,\n",
    "                    #alpha=alpha, max_iter=max_iteration) # optimization\n",
    "    #scores = cross_val_score(nnet, X, y, cv=5, scoring=\"r2\") # cross-validation and calculate r^2 within\n",
    "    #print(scores)\n",
    "    #nnet.fit(Xtrain, ytrain)\n",
    "    #print(nnet.predict(Xtest))\n",
    "\n",
    "\n",
    "#for hidden_layer in hidden_layers:\n",
    "    #for activation_function in activation_functions:\n",
    "        #for solver in solvers:\n",
    "            #for alpha in alphas:\n",
    "                #for max_iteration in max_iterations:\n",
    "                    #train_and_test(hidden_layer, activation_function, solver, alpha, max_iteration)\n",
    "\n",
    "# train_and_test((32, 64, 32), \"relu\", \"sgd\", 0.001, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers = [\"r2\", \"neg_mean_absolute_error\"]\n",
    "parameters= {\n",
    "    \"hidden_layer_sizes\": [(32, 64, 32), (64, 128, 64), (8, 16, 32, 16, 8), (32, 64, 128, 64, 32), (15, 27, 40, 31, 12)],\n",
    "    \"activation\": [\"relu\", \"logistic\", \"tanh\", \"identity\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.0005, 0.00005],\n",
    "    \"max_iter\": [1000, 2000]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(MLPRegressor(), parameters, cv=5, scoring=scorers, refit=False)\n",
    "model.fit(X, y)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "params = model.cv_results_[\"params\"]\n",
    "\n",
    "maes = model.cv_results_[\"mean_test_neg_mean_absolute_error\"]\n",
    "r2s = model.cv_results_[\"mean_test_r2\"]\n",
    "\n",
    "results[\"Params\"] = pd.Series(params)\n",
    "results[\"MeanMAE\"] = -pd.Series(maes)\n",
    "results[\"MeanR2\"] = pd.Series(r2s)\n",
    "\n",
    "results.sort_values(\"MeanR2\", inplace=True)\n",
    "\n",
    "results.to_csv(\"results_nnet.csv\", sep=\";\", index=False)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dsf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f4c25ce9dd1a50de927298dc55a371fca9b9bb0e26aa91c5573ba8ea5976be0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
